{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this activity, we’ll explore ***autoscaling*** for cloud administration. Autoscaling is automatically provisioning a configuration of virtual machines (VMs) to meet an organization’s or an individual’s goals.\n",
    "\n",
    "Deciding upon the best autoscaling policy depends largely on the pattern of the workload that the VM configuration will need to handle. In this activity, we will cover three important types of workload patterns in three scenarios:\n",
    "1. **Monotonically increasing or decreasing.**\n",
    "2. **Step function.**\n",
    "3. **Cyclic with bursts.**\n",
    "\n",
    "For each scenario, we will address four important considerations. Don’t be concerned if you don’t understand these considerations yet — we’ll discuss them both below and during the activity. \n",
    "1. **Whether to autoscale predictively, reactively, or both.**\n",
    "2. **Whether to adjust the number of VMs by a little or a lot.**\n",
    "3. **Whether to aggregate workload and performance metrics over shorter or longer periods of time.**\n",
    "4. **How to minimize costs while meeting quality of service needs.**\n",
    "\n",
    "Following are some points about scaling and elasticity within cloud computing that you will find helpful as you do this activity.\n",
    "\n",
    "- - -\n",
    "\n",
    "The overarching consideration when deciding on a configuration of VMs is ***performance vs. cost***. For instance, consider an enterprise that has an e-commerce site. If they over-provision, they will spend too much money on their cloud configuration and so they will be less efficient than their competitors. If they under-provision, they may fail to meet their quality of service goals, causing them to lose customers and the money they would spend.\n",
    "\n",
    "- - -\n",
    "\n",
    "The two types of autoscaling we will discuss are\n",
    "* **Predictive autoscaling**: Adjusting the configuration of VMs based upon predictions about what the computing needs will be. Any type of scaling takes time, so predictive scaling can be done slightly in advance of the anticipated need to help ensure that the system is ready when the need arises.\n",
    "* **Reactive autoscaling**: Adjusting the configuration of VMs based on measurements, or *metrics*, of the system’s workload and/or performance.  Reactive autoscaling is often necessary because needs cannot always be accurately predicted. Metrics for reactive autoscaling take time and resources. After metrics detect a need, it still takes time to complete the scaling operation. \n",
    "\n",
    "- - -\n",
    "\n",
    "In this activity, we focus on **horizontal scaling** (scaling in or out) due to its advantages over vertical scaling:\n",
    "* ***Flexibility & elasticity***: VMs can be added or removed without downtime as demand changes.\n",
    "* ***Resilience & availability***: Fault tolerance with no single point of failure: If one VM fails, others can take over.\n",
    "* ***Cost-effectiveness***: Finer granularity for precision in VM allocation. With vertical scaling, VMs options are typically relatively coarse — for instance, there might be a gap between choosing a VM with 16 vs. 32 CPU cores. But using horizontal scaling with 2-core VMs, one can allocate VMs so that the number of cores is any even number between 2 and 32 (or more).\n",
    "\n",
    "- - -\n",
    "\n",
    "You will also find the following points helpful.\n",
    "\n",
    "* **All scaling takes time:** While horizontal scaling does not require stopping VM(s), scaling in or out takes time too. First, if you are scaling reactively, it takes time to detect that scaling is necessary (see more about that below). Second, when scaling out, it takes time to provision and start new VMs; conversely, when scaling in (removing VMs), it takes time to complete all of the VMs’ outstanding requests and deregister them.  \n",
    "* **Workload and performance metrics add overhead:** Processes that measure workload and/or performance, then decide whether a scaling operation is necessary, require compute time and resources. Besides taking time, these processes incur costs. \n",
    "* **The optimal time period for workload and performance metrics varies by situation:** Assessing a metric by aggregating measures over a period of time smooths out rapid fluctuations that could occur if metrics were assessed based on a single moment's measurement. If changes in measures can occur quickly and we must react to them quickly, the metrics should be aggregated over shorter periods of time to enable faster reaction. If not, the metrics can be aggregated over longer periods of time.\n",
    "* **Throttling:**  To *throttle* in cloud computing is to reduce the availability of computing resources for one or more users of those resources. For instance, one might throttle by limiting the amount of resources that any one individual can use, or delaying services like report generation. Throttling can preserve resources for more important activities. If there is a sudden but brief burst in demand, throttling may be the only action one needs to take since the demand may have passed by the time additional resources would be available. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
