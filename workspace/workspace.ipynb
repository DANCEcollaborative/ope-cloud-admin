{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The overarching consideration when provisioning virtual machines in the cloud is ***performance vs. cost***:  If you over-provision, you waste money on unused resources; if you under-provision, you lose customers and the money they would spend. \n",
    "\n",
    "In this activity, we focus on **horizontal scaling** (scaling in/out) due to its advantages over vertical scaling:\n",
    "* *Flexibility & elasticity*: Easier to add or remove resources without downtime as demand changes.\n",
    "* *Resilience & availability*: Fault tolerance with no single point of failure. If one node fails, others can take over.\n",
    "* *Cost-effectiveness*: Finer granularity for precision in resource allocation. Can add or remove resources incrementally.\n",
    "\n",
    "Following are some points about scaling and elasticity within cloud computing that you will find helpful as you do this activity.\n",
    "\n",
    "* **Scaling in or out takes time:** While horizontal scaling does not require stopping VM(s), *scaling in or out takes some time too*. First, if you are scaling reactively, it takes time to detect that scaling is necessary (see more about that below). Second, when scaling out, it takes time to provision and start new VMs; conversely, when scaling in (removing VMs), it takes time to complete all of the VMs’ outstanding requests and deregister them.  \n",
    "* **Workload and performance metrics take time and resources:** Processes that measure workload and/or performance, then decide whether a scaling operation is necessary, require compute time and resources as well. Furthermore, these metrics must be assessed over periods of time to avoid making snap decisions based on a single value which may be an outlier. Thus, these processes take time and resources which must be paid for. \n",
    "* **Workload and performance metrics may be aggregated over varying periods of time.** The time periods over which workload and performance metrics should be assessed may vary by situation. Measuring over a period of time smooths out rapid fluctuations that could occur if measures were assessed based on single instances. The amount of time over which to aggregate measures depends on the characteristics of the workload and the performance needs of the application. If sustained changes in workload demands are likely to occur quickly and high performance is important, then measures must be aggregated over relatively short periods of time. Conversely, if neither of these is the case, measures of demand can be smoothed and resources can be saved by aggregating over longer periods of time. \n",
    "* **Throttling can be a temporary alternative for scaling.** As described above, any type of scaling takes time. While waiting for an increase in resources to take effect, you may be able to ***throttle*** some services to preserve resources for more important services. For instance, you might limit the amount of resources that any one individual can use, or delay services like report generation. If there is a sudden but brief burst in demand, throttling may be the only action you need to take since the demand may have passed by the time additional resources would be available. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
